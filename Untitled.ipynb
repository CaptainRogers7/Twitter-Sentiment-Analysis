{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_train = pd.read_csv(\"train.csv\")\n",
    "data_test = pd.read_csv(\"test.csv\")\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
       "1  31964   @user #white #supremacists want everyone to s...\n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3  31966  is the hp and the cursed child book up for res...\n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()\n",
    "#print(len(data_train['id']))\n",
    "#31962\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.concat([data_train,data_test],axis=0,sort=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id  label                                              tweet\n",
      "0          1    0.0   @user when a father is dysfunctional and is s...\n",
      "1          2    0.0  @user @user thanks for #lyft credit i can't us...\n",
      "2          3    0.0                                bihday your majesty\n",
      "3          4    0.0  #model   i love u take with u all the time in ...\n",
      "4          5    0.0             factsguide: society now    #motivation\n",
      "5          6    0.0  [2/2] huge fan fare and big talking before the...\n",
      "6          7    0.0   @user camping tomorrow @user @user @user @use...\n",
      "7          8    0.0  the next school year is the year for exams.ð...\n",
      "8          9    0.0  we won!!! love the land!!! #allin #cavs #champ...\n",
      "9         10    0.0   @user @user welcome here !  i'm   it's so #gr...\n",
      "10        11    0.0   â #ireland consumer price index (mom) climb...\n",
      "11        12    0.0  we are so selfish. #orlando #standwithorlando ...\n",
      "12        13    0.0  i get to see my daddy today!!   #80days #getti...\n",
      "13        14    1.0  @user #cnn calls #michigan middle school 'buil...\n",
      "14        15    1.0  no comment!  in #australia   #opkillingbay #se...\n",
      "15        16    0.0  ouch...junior is angryð#got7 #junior #yugyo...\n",
      "16        17    0.0  i am thankful for having a paner. #thankful #p...\n",
      "17        18    1.0                             retweet if you agree! \n",
      "18        19    0.0  its #friday! ð smiles all around via ig use...\n",
      "19        20    0.0  as we all know, essential oils are not made of...\n",
      "20        21    0.0  #euro2016 people blaming ha for conceded goal ...\n",
      "21        22    0.0  sad little dude..   #badday #coneofshame #cats...\n",
      "22        23    0.0  product of the day: happy man #wine tool  who'...\n",
      "23        24    1.0    @user @user lumpy says i am a . prove it lumpy.\n",
      "24        25    0.0   @user #tgif   #ff to my #gamedev #indiedev #i...\n",
      "25        26    0.0  beautiful sign by vendor 80 for $45.00!! #upsi...\n",
      "26        27    0.0   @user all #smiles when #media is   !! ðð...\n",
      "27        28    0.0  we had a great panel on the mediatization of t...\n",
      "28        29    0.0        happy father's day @user ðððð  \n",
      "29        30    0.0  50 people went to nightclub to have a good nig...\n",
      "...      ...    ...                                                ...\n",
      "49129  49130    NaN  people do anything for fucking attention nowad...\n",
      "49130  49131    NaN  creative bubble got burst ð¢ looking forward...\n",
      "49131  49132    NaN  tomorrow is gonna be a big day! we are going t...\n",
      "49132  49133    NaN  i am thankful for baby giggles. #thankful #pos...\n",
      "49133  49134    NaN  #model   i love u take with u all the time in ...\n",
      "49134  49135    NaN  in life u will grow to learn some pple will wo...\n",
      "49135  49136    NaN  ði was the storm,you were the rain. togethe...\n",
      "49136  49137    NaN  lovelgq -  broken ep via   #rnb #love #heabrok...\n",
      "49137  49138    NaN  spread love not hateâ¤ï¸ðððð #pr...\n",
      "49138  49139    NaN     @user @user are the most racist pay ever!!!!! \n",
      "49139  49140    NaN  i am thankful for children. #thankful #positiv...\n",
      "49140  49141    NaN  liverpool â¤ï¸ð¬ð§ #walk #liverpool #sta...\n",
      "49141  49142    NaN  #bakersfield   rooster simulation: i want to c...\n",
      "49142  49143    NaN  por do sol ó¾â¤ï¸#instagood #beautiful   #...\n",
      "49143  49144    NaN  @user hell yeah what a great surprise for your...\n",
      "49144  49145    NaN  when ur the joke ur defensive towards everythi...\n",
      "49145  49146    NaN  #enjoying the #evening #sun in my #bedroom â¨...\n",
      "49146  49147    NaN  tonight on @user from 9pm gmt  you can here a ...\n",
      "49147  49148    NaN  today is a good day for excercise #imready #so...\n",
      "49148  49149    NaN  good night with a tea and music âï¸ðð...\n",
      "49149  49150    NaN  loving lifeðºð¸âï¸ð  #createyourfutu...\n",
      "49150  49151    NaN  black professor demonizes, proposes nazi style...\n",
      "49151  49152    NaN  learn how to think positive.  #positive   #ins...\n",
      "49152  49153    NaN  we love the pretty, happy and fresh you! #teen...\n",
      "49153  49154    NaN  2_damn_tuff-ruff_muff__techno_city-(ng005)-web...\n",
      "49154  49155    NaN  thought factory: left-right polarisation! #tru...\n",
      "49155  49156    NaN  feeling like a mermaid ð #hairflip #neverre...\n",
      "49156  49157    NaN  #hillary #campaigned today in #ohio((omg)) &am...\n",
      "49157  49158    NaN  happy, at work conference: right mindset leads...\n",
      "49158  49159    NaN  my   song \"so glad\" free download!  #shoegaze ...\n",
      "\n",
      "[49159 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "cleaned_tweets = []\n",
    "\n",
    "for i in range(len(combined_data)):\n",
    "    twt = combined_data['tweet'][i]\n",
    "    twt = re.sub('[^a-zA-Z]',' ',twt)\n",
    "    twt = re.sub(r\"user\",' ',twt)\n",
    "    word_tokens = word_tokenize(twt)\n",
    "    twt = [stemmer.stem(word) for word in word_tokens if word not in stop_words]\n",
    "    twt = ' '.join(twt)\n",
    "    cleaned_tweets.append(twt)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                       0\n",
      "0          father dysfunct selfish drag kid dysfunct run\n",
      "1      thank lyft credit use caus offer wheelchair va...\n",
      "2                                         bihday majesti\n",
      "3                            model love u take u time ur\n",
      "4                                factsguid societi motiv\n",
      "5      huge fan fare big talk leav chao pay disput ge...\n",
      "6                                    camp tomorrow danni\n",
      "7      next school year year exam think school exam h...\n",
      "8      love land allin cav champion cleveland clevela...\n",
      "9                                              welcom gr\n",
      "10     ireland consum price index mom climb previou m...\n",
      "11     selfish orlando standwithorlando pulseshoot or...\n",
      "12                      get see daddi today day gettingf\n",
      "13     cnn call michigan middl school build wall chan...\n",
      "14     comment australia opkillingbay seashepherd hel...\n",
      "15              ouch junior angri got junior yugyoem omg\n",
      "16                               thank paner thank posit\n",
      "17                                          retweet agre\n",
      "18           friday smile around via ig cooki make peopl\n",
      "19                          know essenti oil made chemic\n",
      "20     euro peopl blame ha conced goal fat rooney gav...\n",
      "21     sad littl dude badday coneofsham cat piss funn...\n",
      "22     product day happi man wine tool weekend time o...\n",
      "23                                 lumpi say prove lumpi\n",
      "24           tgif ff gamedev indiedev indiegamedev squad\n",
      "25     beauti sign vendor upsideofflorida shopalyssa ...\n",
      "26     smile media pressconfer antalya turkey sunday ...\n",
      "27                  great panel mediat public servic ica\n",
      "28                                      happi father day\n",
      "29     peopl went nightclub good night man action mea...\n",
      "...                                                  ...\n",
      "49129                    peopl anyth fuck attent nowaday\n",
      "49130  creativ bubbl got burst look forward day never...\n",
      "49131  tomorrow gon na big day go deliv first box boo...\n",
      "49132                       thank babi giggl thank posit\n",
      "49133                        model love u take u time ur\n",
      "49134  life u grow learn pple work fuck u coz ur life...\n",
      "49135  storm rain togeth destroy town becam name myqu...\n",
      "49136  lovelgq broken ep via rnb love heabroken hea d...\n",
      "49137  spread love hate prayingfororlando loveanoth t...\n",
      "49138                                    racist pay ever\n",
      "49139                         thank children thank posit\n",
      "49140  liverpool walk liverpool starbuck avidaeboa pa...\n",
      "49141  bakersfield rooster simul want climb vast expa...\n",
      "49142  por sol instagood beauti instadaili instalik i...\n",
      "49143  hell yeah great surpris present enjoy pictur b...\n",
      "49144                   ur joke ur defens toward everyth\n",
      "49145  enjoy even sun bedroom cozi even homesweethom ...\n",
      "49146  tonight pm gmt special earli play new song upc...\n",
      "49147  today good day excercis imreadi sofuckenreadi ...\n",
      "49148  good night tea music billi music tea mug tokio...\n",
      "49149  love life createyourfutur lifestyl holiday la ...\n",
      "49150  black professor demon propos nazi style confis...\n",
      "49151        learn think posit posit instagram instagood\n",
      "49152  love pretti happi fresh teenilici fixdermateen...\n",
      "49153  damn tuff ruff muff techno citi ng web ukhx in...\n",
      "49154  thought factori left right polaris trump usele...\n",
      "49155  feel like mermaid hairflip neverreadi formal w...\n",
      "49156  hillari campaign today ohio omg amp use word l...\n",
      "49157  happi work confer right mindset lead cultur de...\n",
      "49158     song glad free download shoegaz newmus newsong\n",
      "\n",
      "[49159 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(cleaned_tweets)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'label', 'tweet', 'cleaned tweets'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "combined_data['cleaned tweets'] = df\n",
    "print(combined_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
